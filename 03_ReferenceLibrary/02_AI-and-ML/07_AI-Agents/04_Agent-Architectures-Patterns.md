# 04_Agent-Architectures-Patterns

**Learning Level**: Intermediate to Advanced  
**Prerequisites**: Understanding of AI Agent fundamentals, basic software architecture  
**Estimated Time**: 120 minutes  

## ðŸŽ¯ Learning Objectives

By the end of this content, you will:

- Master the core architectural patterns used in modern AI agents
- Understand when to apply each pattern for different use cases
- Design agent architectures that balance capability and reliability
- Implement planning and reasoning strategies for complex scenarios
- Evaluate trade-offs between different architectural approaches

---

## ðŸ—ï¸ Core Agent Architecture Patterns

Modern AI agents follow established architectural patterns that have evolved from research and practical implementation. Understanding these patterns is crucial for building effective, reliable agent systems.

### **Pattern Selection Framework**

```text
Simple Task â”€â”€â”€â”€â–º ReAct Pattern
     â”‚
Complex Planning â”€â”€â”€â”€â–º Plan-and-Execute
     â”‚
Learning/Adaptation â”€â”€â”€â”€â–º Reflexion Pattern
     â”‚
Exploration/Creativity â”€â”€â”€â”€â–º Tree of Thoughts
     â”‚
Multi-Domain â”€â”€â”€â”€â–º Hierarchical Agents
```

---

## ðŸ”„ ReAct Pattern: Reasoning and Acting

### **Pattern Overview**

**ReAct** (Reasoning + Acting) is the most fundamental agent pattern that interleaves reasoning steps with action execution. The agent thinks about what to do, takes an action, observes the result, and continues this cycle until the goal is achieved.

### **Core Components**

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Thought      â”‚ â”€â”€â–º Analyze current situation
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Action      â”‚ â”€â”€â–º Take specific action
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Observation    â”‚ â”€â”€â–º Process action results
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Loop back to Thought
```

### **Implementation Pattern**

```python
class ReActAgent:
    def __init__(self, llm, tools):
        self.llm = llm
        self.tools = tools
        self.history = []
    
    def execute(self, goal):
        self.history.append(f"Goal: {goal}")
        
        while not self.is_goal_achieved(goal):
            # Reasoning phase
            thought = self.llm.generate(
                prompt=self.create_reasoning_prompt(),
                context=self.history
            )
            self.history.append(f"Thought: {thought}")
            
            # Action selection
            action = self.select_action(thought)
            self.history.append(f"Action: {action}")
            
            # Action execution
            result = self.execute_action(action)
            self.history.append(f"Observation: {result}")
            
            # Check for completion or failure
            if self.should_terminate():
                break
        
        return self.extract_final_result()
    
    def create_reasoning_prompt(self):
        return f"""
        Based on your goal and the conversation history below, 
        think step by step about what you should do next.
        
        History:
        {chr(10).join(self.history[-10:])}  # Last 10 steps
        
        Available tools: {list(self.tools.keys())}
        
        Think: What should I do next to achieve the goal?
        """
```

### **Real-World Example: Research Assistant**

```text
Goal: "Research the current state of electric vehicle adoption in Europe"

Cycle 1:
Thought: I need to find recent statistics and reports on EV adoption in Europe
Action: search_web("electric vehicle adoption Europe 2024 statistics")
Observation: Found articles from IEA, BloombergNEF, and European Commission

Cycle 2:
Thought: I should get specific data from authoritative sources like IEA
Action: fetch_content("https://iea.org/reports/ev-outlook-2024")
Observation: Retrieved comprehensive report with European EV market data

Cycle 3:
Thought: Need to extract key statistics and trends from this report
Action: analyze_document("Focus on European market share, growth rates, policy impact")
Observation: Extracted key findings: 23% market share, 15% growth, policy drivers

Cycle 4:
Thought: Should compile findings into a structured summary
Action: generate_summary("European EV adoption trends, data, and policy impact")
Observation: Created comprehensive summary with statistics and analysis
```

### **ReAct Pattern Strengths**

- **Transparency**: Clear reasoning trail for debugging and auditing
- **Adaptability**: Can adjust strategy based on intermediate results
- **Tool Integration**: Natural framework for incorporating external tools
- **Simplicity**: Easy to understand and implement

### **ReAct Pattern Limitations**

- **Local Optimization**: May get stuck in suboptimal solution paths
- **Limited Planning**: No long-term strategic planning capability
- **Context Growth**: History can become unwieldy for complex tasks
- **Error Propagation**: Mistakes in early steps can compound

---

## ðŸŽ¯ Plan-and-Execute Pattern

### **Plan-and-Execute Overview**

The **Plan-and-Execute** pattern separates high-level planning from detailed execution. The agent first creates a comprehensive plan, then executes each step while monitoring progress and adapting as needed.

### **Architecture Components**

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Planner      â”‚ â”€â”€â–º Create high-level strategy
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Executor     â”‚ â”€â”€â–º Execute individual steps
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Monitor      â”‚ â”€â”€â–º Track progress and adapt
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Re-planner    â”‚ â”€â”€â–º Revise plan when needed
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Implementation Framework**

```python
class PlanAndExecuteAgent:
    def __init__(self, llm, tools):
        self.llm = llm
        self.tools = tools
        self.planner = PlannerComponent(llm)
        self.executor = ExecutorComponent(llm, tools)
        self.monitor = MonitorComponent(llm)
    
    def execute(self, goal):
        # Phase 1: Create comprehensive plan
        plan = self.planner.create_plan(goal)
        print(f"Initial Plan: {plan}")
        
        # Phase 2: Execute plan with monitoring
        results = []
        for step_idx, step in enumerate(plan.steps):
            # Execute current step
            result = self.executor.execute_step(step)
            results.append(result)
            
            # Monitor progress and check for issues
            status = self.monitor.assess_progress(
                plan=plan,
                current_step=step_idx,
                results=results,
                goal=goal
            )
            
            # Adapt plan if necessary
            if status.needs_replanning:
                plan = self.planner.revise_plan(
                    original_plan=plan,
                    current_progress=results,
                    issue=status.issue
                )
                print(f"Revised Plan: {plan}")
        
        return self.compile_final_result(results)

class PlannerComponent:
    def create_plan(self, goal):
        planning_prompt = f"""
        Create a detailed, step-by-step plan to achieve: {goal}
        
        Consider:
        - Dependencies between steps
        - Required resources and tools
        - Potential failure points
        - Success criteria for each step
        
        Format as numbered steps with clear actions and expected outcomes.
        """
        
        plan_text = self.llm.generate(planning_prompt)
        return self.parse_plan(plan_text)
```

### **Real-World Example: Event Planning Agent**

```text
Goal: "Organize a corporate tech conference for 200 attendees"

Planning Phase:
Step 1: Define conference scope (topic, audience, budget, dates)
Step 2: Secure venue (capacity, tech requirements, catering)
Step 3: Recruit speakers (keynotes, panels, workshops)
Step 4: Setup registration and marketing
Step 5: Coordinate logistics (A/V, materials, staffing)
Step 6: Execute event and gather feedback

Execution with Adaptation:
Step 1 Execution: âœ“ Completed - AI/ML focus, $50k budget, Oct 15-16
Step 2 Execution: âš ï¸ Issue - Preferred venue unavailable for October
Step 2 Re-planning: Find alternative venues or adjust dates
Step 2 Re-execution: âœ“ Secured backup venue with better A/V setup
[Continue through remaining steps...]
```

### **Plan-and-Execute Strengths**

- **Strategic Thinking**: Comprehensive upfront planning reduces execution errors
- **Efficiency**: Clear roadmap prevents redundant or unnecessary actions
- **Adaptability**: Can revise plans when circumstances change
- **Accountability**: Clear success criteria for each step

### **Plan-and-Execute Limitations**

- **Planning Overhead**: Significant upfront time investment
- **Rigidity**: May over-commit to initial plan when flexibility is needed
- **Planning Quality**: Effectiveness depends heavily on initial planning quality
- **Context Sensitivity**: May not adapt quickly to rapidly changing environments

---

## ðŸ”„ Reflexion Pattern: Learning from Experience

### **Reflexion Overview**

The **Reflexion** pattern enables agents to learn from their mistakes and improve performance over time. After completing a task, the agent reflects on what worked, what didn't, and how to improve future performance.

### **Learning Cycle**

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Execute      â”‚ â”€â”€â–º Attempt to achieve goal
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Evaluate     â”‚ â”€â”€â–º Assess performance quality
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Reflect      â”‚ â”€â”€â–º Analyze failures and successes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Learn       â”‚ â”€â”€â–º Update strategies and knowledge
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Apply to next execution
```

### **Reflexion Implementation**

```python
class ReflexionAgent:
    def __init__(self, llm, tools):
        self.llm = llm
        self.tools = tools
        self.memory = ExperienceMemory()
        self.max_iterations = 3
    
    def execute_with_learning(self, goal):
        for iteration in range(self.max_iterations):
            # Retrieve relevant past experiences
            past_experiences = self.memory.retrieve_similar(goal)
            
            # Execute attempt with learned strategies
            attempt_result = self.execute_attempt(
                goal=goal,
                iteration=iteration,
                past_experiences=past_experiences
            )
            
            # Evaluate performance
            evaluation = self.evaluate_performance(
                goal=goal,
                result=attempt_result
            )
            
            # If successful, return result
            if evaluation.success:
                self.memory.store_success(goal, attempt_result, evaluation)
                return attempt_result
            
            # Reflect on failures and generate improvements
            reflection = self.reflect_on_failure(
                goal=goal,
                attempt=attempt_result,
                evaluation=evaluation,
                past_experiences=past_experiences
            )
            
            # Store learning for next iteration
            self.memory.store_failure_learning(goal, reflection)
        
        # Return best attempt if no success achieved
        return self.get_best_attempt()
    
    def reflect_on_failure(self, goal, attempt, evaluation, past_experiences):
        reflection_prompt = f"""
        Task: {goal}
        Attempt: {attempt}
        Evaluation: {evaluation.feedback}
        
        Past similar experiences: {past_experiences}
        
        Analyze what went wrong and how to improve:
        1. What specific actions or decisions led to failure?
        2. What alternative approaches could work better?
        3. What additional information or tools are needed?
        4. How can similar mistakes be avoided in the future?
        
        Provide specific, actionable improvements for the next attempt.
        """
        
        return self.llm.generate(reflection_prompt)
```

### **Real-World Example: Code Debugging Agent**

```text
Goal: "Fix the performance issue in the user authentication service"

Attempt 1:
Action: Reviewed code for obvious bottlenecks
Result: Identified database query in login loop
Fix Applied: Added database connection pooling
Evaluation: Partial improvement (20% faster) but still slow

Reflection: "Connection pooling helped but didn't solve root cause. 
Need to analyze actual query performance and database indexes."

Attempt 2:
Action: Profiled database queries with EXPLAIN ANALYZE
Result: Found missing index on frequently queried user_sessions table
Fix Applied: Added composite index on (user_id, created_at)
Evaluation: Significant improvement (70% faster) but occasional timeouts

Reflection: "Index dramatically improved normal case performance. 
Timeouts suggest need to handle concurrent session cleanup differently."

Attempt 3:
Action: Implemented background job for session cleanup
Result: Moved expensive cleanup operations out of request path
Fix Applied: Background worker + optimized cleanup queries
Evaluation: Success - consistent fast performance, no timeouts

Learning Stored: "Authentication performance issues often involve 
both query optimization AND background processing separation."
```

### **Reflexion Pattern Strengths**

- **Continuous Improvement**: Gets better at similar tasks over time
- **Error Analysis**: Systematic approach to understanding failures
- **Knowledge Accumulation**: Builds reusable experience base
- **Adaptability**: Learns to handle edge cases and variations

### **Reflexion Pattern Limitations**

- **Iteration Overhead**: Multiple attempts increase time and resource costs
- **Learning Quality**: Depends on quality of reflection and evaluation
- **Memory Management**: Storing and retrieving experiences effectively is complex
- **Generalization**: May overfit to specific scenarios

---

## ðŸŒ³ Tree of Thoughts Pattern

### **Tree of Thoughts Overview**

The **Tree of Thoughts** pattern enables agents to explore multiple reasoning paths simultaneously, evaluating different approaches before committing to a solution. This is particularly effective for creative or complex problem-solving scenarios.

### **Exploration Strategy**

```text
                    Initial Problem
                         â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚        â”‚        â”‚
            Approach A  Approach B  Approach C
                â”‚        â”‚        â”‚
           â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”    â”‚    â”Œâ”€â”€â”€â”¼â”€â”€â”€â”€â”
           â”‚    â”‚   â”‚    â”‚    â”‚   â”‚    â”‚
         A1   A2   A3   B1   C1  C2   C3
                            â”‚
                       â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”
                       â”‚    â”‚    â”‚
                     C1a  C1b  C1c
```

### **Tree of Thoughts Implementation**

```python
class TreeOfThoughtsAgent:
    def __init__(self, llm, tools):
        self.llm = llm
        self.tools = tools
        self.max_depth = 3
        self.max_branches = 3
    
    def solve_problem(self, problem):
        # Generate initial thought branches
        initial_thoughts = self.generate_initial_approaches(problem)
        
        # Build and evaluate thought tree
        thought_tree = ThoughtTree(problem)
        
        for thought in initial_thoughts:
            self.explore_branch(
                tree=thought_tree,
                current_thought=thought,
                depth=0,
                problem=problem
            )
        
        # Select best solution path
        best_path = thought_tree.find_best_path()
        
        # Execute the selected solution
        return self.execute_solution_path(best_path)
    
    def explore_branch(self, tree, current_thought, depth, problem):
        if depth >= self.max_depth:
            return
        
        # Evaluate current thought
        evaluation = self.evaluate_thought(current_thought, problem)
        tree.add_node(current_thought, evaluation)
        
        # If promising, generate next level thoughts
        if evaluation.score > 0.6:  # Threshold for exploration
            next_thoughts = self.generate_next_thoughts(
                current_thought, problem
            )
            
            for next_thought in next_thoughts[:self.max_branches]:
                self.explore_branch(
                    tree, next_thought, depth + 1, problem
                )
    
    def generate_initial_approaches(self, problem):
        prompt = f"""
        Problem: {problem}
        
        Generate 3 fundamentally different approaches to solve this problem.
        For each approach, provide:
        1. Core strategy
        2. Key advantages
        3. Potential challenges
        
        Focus on diversity of thinking rather than immediate feasibility.
        """
        
        approaches_text = self.llm.generate(prompt)
        return self.parse_approaches(approaches_text)
    
    def evaluate_thought(self, thought, problem):
        evaluation_prompt = f"""
        Problem: {problem}
        Proposed approach: {thought}
        
        Evaluate this approach on:
        1. Feasibility (0-1): How likely is this to work?
        2. Completeness (0-1): How fully does this address the problem?
        3. Efficiency (0-1): How resource-efficient is this approach?
        4. Innovation (0-1): How creative/novel is this solution?
        
        Provide scores and brief reasoning for each dimension.
        """
        
        evaluation_text = self.llm.generate(evaluation_prompt)
        return self.parse_evaluation(evaluation_text)
```

### **Real-World Example: Marketing Strategy Development**

```text
Problem: "Increase product adoption for our new AI-powered productivity tool"

Initial Approaches:
A. Content Marketing + Thought Leadership
B. Partnership + Integration Strategy  
C. Community Building + User-Generated Content

Branch A Exploration:
A1: Technical blog posts + case studies
A2: Video demonstrations + tutorials
A3: Industry conference speaking + workshops

Branch B Exploration:
B1: Integration with Slack, Teams, Notion
B2: Partner with productivity consultants
B3: White-label for enterprise customers

Branch C Exploration:
C1: Build user community platform
C2: Incentivize user success stories
C3: Create certification program

Evaluation Results:
A2 (Video demos): High feasibility, good completeness, efficient
B1 (Integrations): High feasibility, excellent completeness, resource-intensive
C2 (Success stories): Medium feasibility, good completeness, very efficient

Selected Strategy: Combination of A2 + B1 + C2
- Core: Video demonstrations showing integrations
- Amplify: User success stories and testimonials
- Distribution: Through partner channels
```

### **Tree of Thoughts Strengths**

- **Comprehensive Exploration**: Considers multiple solution approaches
- **Quality Optimization**: Evaluates and compares alternatives
- **Creative Solutions**: Encourages novel and innovative thinking
- **Risk Mitigation**: Identifies potential issues before full commitment

### **Tree of Thoughts Limitations**

- **Computational Overhead**: Exploring multiple branches is resource-intensive
- **Complexity**: Difficult to implement and debug effectively
- **Evaluation Quality**: Depends on accurate assessment of thought quality
- **Paralysis**: May over-analyze instead of taking action

---

## ðŸ”— Pattern Combination Strategies

### **Hybrid Architectures**

Real-world agents often combine multiple patterns for optimal performance:

#### **ReAct + Reflexion**

```python
class AdaptiveReActAgent:
    def __init__(self, llm, tools):
        self.react_engine = ReActAgent(llm, tools)
        self.reflexion_engine = ReflexionAgent(llm, tools)
    
    def execute(self, goal):
        # Use Reflexion for complex/novel tasks
        if self.is_complex_task(goal):
            return self.reflexion_engine.execute_with_learning(goal)
        
        # Use ReAct for routine tasks
        return self.react_engine.execute(goal)
```

#### **Plan-and-Execute + Tree of Thoughts**

```python
class StrategicPlanningAgent:
    def __init__(self, llm, tools):
        self.tot_planner = TreeOfThoughtsAgent(llm, tools)
        self.plan_executor = PlanAndExecuteAgent(llm, tools)
    
    def execute(self, goal):
        # Use Tree of Thoughts for strategic planning
        strategy = self.tot_planner.solve_problem(goal)
        
        # Use Plan-and-Execute for implementation
        return self.plan_executor.execute(strategy)
```

### **Pattern Selection Guidelines**

| Pattern | Best For | Avoid When |
|---------|----------|------------|
| **ReAct** | Straightforward tasks, tool-heavy workflows | Complex planning, creative problems |
| **Plan-and-Execute** | Multi-step projects, clear objectives | Rapidly changing requirements |
| **Reflexion** | Repeated similar tasks, learning scenarios | One-off tasks, time-critical |
| **Tree of Thoughts** | Creative problems, strategy development | Simple tasks, resource constraints |

---

## ðŸ”— Related Topics

### **Prerequisites**

- **[01_AI-Agent-Fundamentals.md](01_AI-Agent-Fundamentals.md)** - Core agent concepts and capabilities
- **[../01_AI/03_AI-Fundamentals-Overview.md](../01_AI/03_AI-Fundamentals-Overview.md)** - LLM and AI foundations

### **Related**

- **[03_Agent-Development-Fundamentals.md](03_Agent-Development-Fundamentals.md)** - Hands-on implementation of these patterns
- **[04_Multi-Agent-Systems.md](04_Multi-Agent-Systems.md)** - Scaling patterns to multiple agents

### **Advanced**

- **[05_Agentic-AI-Advanced-Systems.md](05_Agentic-AI-Advanced-Systems.md)** - Sophisticated reasoning and emergent behaviors
- **[06_Agent-Production-Deployment.md](06_Agent-Production-Deployment.md)** - Production considerations for different patterns

---

## ðŸš€ Next Steps

1. **Pattern Analysis**: Identify which patterns apply to your use cases
2. **Framework Research**: Explore how LangChain, CrewAI, or Semantic Kernel implement these patterns
3. **Prototype Development**: Build simple implementations of each pattern
4. **Performance Comparison**: Test different patterns on the same problem
5. **Hybrid Design**: Design agents that combine multiple patterns effectively

---

**ðŸ’¡ Key Takeaway**: Agent architecture patterns provide proven frameworks for different types of reasoning and problem-solving. The key to effective agent design is selecting the right pattern (or combination) for your specific use case, balancing capability, complexity, and resource requirements.
