# 2025-08-12 — Capture-only Notes

- What I did (bullets):
  - Explored Bag-of-Words (counts per vocabulary item; order ignored)
  - Built a tiny counts table for a 3-sentence corpus
  - Compared BoW vs One-Hot at a glance
- Snippets / commands (if any):
  - —
- Links / sources (optional):
  - Reference page: [02_Bag-of-Words](../../03_ReferenceLibrary/02_AI-and-ML/04_NaturalLanguageProcessing/01_Basics/02_Bag-of-Words.md)
  - Canonical code (external): [llm-agents-learning](https://github.com/Swamy-s-Tech-Skills-Academy-AI-ML-Data/llm-agents-learning)
- Insight (one takeaway):
  - BoW is a simple baseline; TF-IDF is a natural next step to reweight common words
- Next tiny step (tomorrow):
  - Implement a minimal TF-IDF and inspect top terms per sentence

## Migration

- Concept captured in Reference Library: [02_Bag-of-Words](../../03_ReferenceLibrary/02_AI-and-ML/04_NaturalLanguageProcessing/01_Basics/02_Bag-of-Words.md)
- Canonical code: [llm-agents-learning](https://github.com/Swamy-s-Tech-Skills-Academy-AI-ML-Data/llm-agents-learning)
